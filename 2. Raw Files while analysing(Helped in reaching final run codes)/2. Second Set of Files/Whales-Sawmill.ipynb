{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "433872ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries successfully imported\n"
     ]
    }
   ],
   "source": [
    "#import all the necessary libraries\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx.algorithms.community as nx_comm\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "print(\"Libraries successfully imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c8ea4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All functions are ready to use\n"
     ]
    }
   ],
   "source": [
    "#all the side functions\n",
    "def generate_chrom(nodes_length,Adj):\n",
    "    chrom = np.array([],dtype=int)\n",
    "    for x in range(nodes_length):\n",
    "        rand = np.random.randint(0,nodes_length)\n",
    "        while Adj[x,rand] != 1:\n",
    "            rand = np.random.randint(0,nodes_length)\n",
    "        chrom = np.append(chrom,rand)\n",
    "    return chrom\n",
    "\n",
    "def merge_subsets(sub):\n",
    "    arr =[]\n",
    "    to_skip=[]\n",
    "    for s in range(len(sub)):\n",
    "        if sub[s] not in to_skip:\n",
    "            new = sub[s]\n",
    "            for x in sub:\n",
    "                if sub[s] & x:\n",
    "                    new = new | x\n",
    "                    to_skip.append(x)\n",
    "            arr.append(new)\n",
    "    return arr\n",
    "\n",
    "def find_subsets(chrom):\n",
    "    sub = [{x,chrom[x]} for x in range(len(chrom))]\n",
    "    result=sub\n",
    "    i=0\n",
    "    while i<len(result):\n",
    "        candidate = merge_subsets(result)\n",
    "        if candidate != result:\n",
    "            result = candidate\n",
    "        else:\n",
    "            break\n",
    "        result=candidate\n",
    "        i+=1\n",
    "    return result\n",
    "\n",
    "def community_score(chrom,subsets,r,Adj):\n",
    "    matrix = Adj.toarray()\n",
    "    CS=0\n",
    "    for s in subsets:\n",
    "        submatrix = np.zeros((len(chrom),len(chrom)),dtype=int)\n",
    "        for i in s:\n",
    "            for j in s:\n",
    "                submatrix[i][j]=matrix[i][j]\n",
    "        M=0\n",
    "        v=0\n",
    "        PS=0\n",
    "        for row in list(s):\n",
    "            ki = np.sum(matrix[row])\n",
    "            kiin = np.sum(submatrix[row])\n",
    "            kiout = ki - kiin\n",
    "            P= kiin/ki\n",
    "            PS+=P\n",
    "            row_mean = kiin/len(s)\n",
    "            v+=np.sum(submatrix[row])\n",
    "            M+=(row_mean**r)/len(s)\n",
    "        CS+=M*v\n",
    "    OS= 0.5*CS/len(subsets) + 0.5*(1/PS)*len(subsets)  #Overall score is calculated by maximizing CS and min PS\n",
    "    return OS\n",
    "\n",
    "def roulette_selection(df_elites):\n",
    "    prob = np.random.random_sample()\n",
    "    sum_cs=np.sum(df_elites[\"community_score\"])\n",
    "    x=0\n",
    "    selected = 0\n",
    "    for i in df_elites.index:\n",
    "        x += df_elites[\"community_score\"][i]\n",
    "        X=x/sum_cs\n",
    "        if prob < X:\n",
    "            chosen=i\n",
    "            break\n",
    "    return chosen\n",
    "\n",
    "def uniform_crossover_GE(parent_1,parent_2,crossover_rate):\n",
    "    if np.random.random_sample() < crossover_rate:\n",
    "        length = len(parent_1)\n",
    "        mask = np.random.randint(2, size=length)\n",
    "        child = np.zeros(length,dtype=int)\n",
    "        for i in range(len(mask)):\n",
    "            if mask[i] == 1:\n",
    "                child[i]=parent_1[i]\n",
    "            else:\n",
    "                child[i]=parent_2[i]\n",
    "        return child\n",
    "    else:\n",
    "        return np.array([])\n",
    "\n",
    "def crossover_DE(parent,trial,crossover_rate):\n",
    "    if np.random.random_sample() >= crossover_rate:\n",
    "        length = len(parent['chrom'])\n",
    "        mask = np.random.randint(2, size=length)\n",
    "        child = np.zeros(length,dtype=int)\n",
    "        for i in range(len(mask)):\n",
    "            if mask[i] == 1:\n",
    "                child[i]=trial[i]\n",
    "            else:\n",
    "                child[i]=parent['chrom'][i]\n",
    "        return child\n",
    "    else:\n",
    "        return trial\n",
    "    \n",
    "def mutation_GE(chrom,Adj,mutation_rate):\n",
    "    if np.random.random_sample() < mutation_rate:\n",
    "        chrom = chrom\n",
    "        neighbor = []\n",
    "        while len(neighbor) < 2:\n",
    "            mutant = np.random.randint(1,len(chrom))\n",
    "            row = Adj[mutant].toarray()[0]\n",
    "            neighbor = [i for i in range(len(row)) if row[i]==1]\n",
    "            if len(neighbor) > 1:\n",
    "                neighbor.remove(chrom[mutant])\n",
    "                to_change=int(np.floor(np.random.random_sample()*(len(neighbor))))\n",
    "                chrom[mutant]=neighbor[to_change]\n",
    "                neighbor.append(chrom[mutant])\n",
    "    return chrom\n",
    "\n",
    "def mutation_DE(parent , target , rand1 , rand2 ,Adj,mutation_rate):\n",
    "    trial = []\n",
    "    for i in range(0,len(parent['chrom'])):\n",
    "        temp = target['chrom'][i] + mutation_rate*(rand1['chrom'][i] - rand2['chrom'][i])\n",
    "        temp = int(temp)\n",
    "        if temp < 0 or temp >= Adj.shape[0] or Adj[i,temp]==0:\n",
    "            temp = target['chrom'][i]\n",
    "        trial.append(temp)\n",
    "    return trial\n",
    "\n",
    "#NMI\n",
    "def entropy(nums):\n",
    "    z = np.bincount(nums)\n",
    "    N = len(nums)\n",
    "    assert nums.shape == (N, )\n",
    "    ent = 0.0\n",
    "    for e in z:\n",
    "        if e != 0:\n",
    "            p = float(e) / N\n",
    "            ent += p*math.log(p)\n",
    "    assert ent <= 0\n",
    "    ent = -ent\n",
    "    assert ent >=0\n",
    "    return ent\n",
    "\n",
    "def computeNMI(clusters, classes):\n",
    "    assert clusters.shape == classes.shape\n",
    "    A = np.c_[(clusters, classes)]\n",
    "    A = np.array(A)\n",
    "    N = A.shape[0]\n",
    "    assert A.shape == (N, 2)\n",
    "    H_clusters = entropy(A[:, 0])\n",
    "    H_classes = entropy(A[:, 1])\n",
    "    NMI = 0.0\n",
    "    for k in np.unique(A[:, 0]):\n",
    "        z = A[A[:, 0] == k, 1]\n",
    "        len_wk = len(z)\n",
    "        t = A[:, 1]\n",
    "        for e in np.unique(z):\n",
    "            wk_cj=len(z[z==e])\n",
    "            len_cj=len(t[t == e])\n",
    "            assert wk_cj <= len_cj\n",
    "            numerator= (float(wk_cj) / float(N)) * math.log( (N*wk_cj) / float(len_wk * len_cj)  )\n",
    "            NMI += numerator\n",
    "    NMI /= float((H_clusters + H_classes) * 0.5)\n",
    "\n",
    "    assert (NMI > 0.0 or abs(NMI) < 1e-10) and (NMI < 1.0 or abs(NMI - 1.0) < 1e-10)\n",
    "    return NMI\n",
    "\n",
    "def check_res(res,Adj):\n",
    "    print(res)\n",
    "    for i in range(0,len(res)):\n",
    "        if Adj[i,res[i]] ==0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def print_graph(graph, result, nodes):\n",
    "    colors = []\n",
    "    for i in range(0, len(result)):\n",
    "        colors.append('#%06X' % np.random.randint(0, 0xFFFFFF))\n",
    "    col_arr = ['']*len(nodes)\n",
    "    for i in range(0,len(result)):\n",
    "        for j in result[i]:\n",
    "            col_arr[j-1] = colors[i]\n",
    "    nx.draw(graph, with_labels=True,node_color = col_arr)\n",
    "    plt.show()\n",
    "print(\"All functions are ready to use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f5a4ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GE loaded to use\n"
     ]
    }
   ],
   "source": [
    "#genetic evolution main function\n",
    "def genetic_evolution(nodes,edges,population=15,generation=100,r=1.5):\n",
    "    graph = []\n",
    "    graph=nx.Graph()\n",
    "    graph.add_nodes_from(nodes) #adds nodes\n",
    "    graph.add_edges_from(edges) #add edges\n",
    "    Adj = nx.adjacency_matrix(graph)\n",
    "    nodes_length = len(graph.nodes())\n",
    "#     nx.draw(graph, with_labels=True,node_color = \"red\")\n",
    "#     plt.show()\n",
    "    # Generates chromosomes? basically gives chrom array population value times\n",
    "    d = {\"chrom\":[generate_chrom(nodes_length,Adj) for n in range(population)]}\n",
    "    #makes data frame of data set d\n",
    "    dframe = pd.DataFrame(data= d)\n",
    "    dframe[\"subsets\"] = dframe[\"chrom\"].apply(find_subsets)\n",
    "    dframe[\"community_score\"]=dframe.apply(lambda x: community_score(x[\"chrom\"],x[\"subsets\"],r,Adj),axis=1)\n",
    "    #Start iterating\n",
    "    gen = 0\n",
    "    population_count = population\n",
    "    while gen < generation:\n",
    "        for i in range(int(np.floor(population/10))):\n",
    "            p1 = 0\n",
    "            p2 = 0\n",
    "            elites = dframe.sort_values(\"community_score\",ascending=True)[int(np.floor(population/10)):]\n",
    "            p1 = roulette_selection(elites)\n",
    "            p2 = roulette_selection(elites)\n",
    "            child=uniform_crossover_GE(dframe[\"chrom\"][p1],dframe[\"chrom\"][p2],0.8)\n",
    "            if len(child)==0:\n",
    "                continue\n",
    "            child=mutation_GE(child,Adj,0.2)\n",
    "            child_subsets = find_subsets(child)\n",
    "            child_cs = community_score(child,child_subsets,r,Adj)\n",
    "            dframe.loc[population_count]=[child,child_subsets,child_cs]\n",
    "            population_count += 1\n",
    "        dfsorted = dframe.sort_values(\"community_score\",ascending=False)\n",
    "        to_drop = dfsorted.index[population:]\n",
    "        dframe.drop(to_drop,inplace=True)\n",
    "        gen +=1  \n",
    "    sorted_df = dframe.sort_values(\"community_score\",ascending=False).index[0]\n",
    "    nodes_subsets = dframe[\"subsets\"][sorted_df]\n",
    "    nodes_list = list(graph.nodes())\n",
    "    #getting result\n",
    "    result = []\n",
    "    for subs in nodes_subsets:\n",
    "        subset = []\n",
    "        for n in subs:\n",
    "            subset.append(nodes_list[n])\n",
    "        result.append(subset)\n",
    "    NMI = 0\n",
    "    clu = dframe.loc[sorted_df]\n",
    "    clu = clu['chrom']\n",
    "    clu = np.array(clu)\n",
    "    for index, target in dframe.iterrows():\n",
    "        temp = np.array(target['chrom'])\n",
    "        x = computeNMI(clu,temp)\n",
    "        NMI += x\n",
    "    NMI /= len(dframe)\n",
    "    modularity = nx_comm.modularity(graph, result)\n",
    "#     print('NMI: ',NMI)\n",
    "#     print('MODULARITY: ', modularity)\n",
    "#     print_graph(graph, result, nodes)\n",
    "    return result, NMI, modularity\n",
    "print(\"GE loaded to use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d91f7afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DE loaded to use\n"
     ]
    }
   ],
   "source": [
    "#differential evolution main function\n",
    "def differential_evolution(nodes,edges,population=15,generation=100,r=1.5):\n",
    "    graph=nx.Graph() \n",
    "    graph.add_nodes_from(nodes) #adds nodes\n",
    "    graph.add_edges_from(edges) #add edges\n",
    "    Adj = nx.adjacency_matrix(graph) \n",
    "    nodes_length = len(graph.nodes())\n",
    "#     nx.draw(graph, with_labels=True,node_color = \"red\")\n",
    "#     plt.show()\n",
    "    d = {\"chrom\":[generate_chrom(nodes_length,Adj) for n in range(population)]}\n",
    "    dframe = pd.DataFrame(data= d)\n",
    "    dframe[\"subsets\"] = dframe[\"chrom\"].apply(find_subsets)\n",
    "    dframe[\"community_score\"]=dframe.apply(lambda x: community_score(x[\"chrom\"],x[\"subsets\"],r,Adj),axis=1)\n",
    "    gen = 0\n",
    "    population_count = population\n",
    "    while gen < generation:\n",
    "        for i in range(int(np.floor(population/10))):\n",
    "            elites = dframe.sort_values(\"community_score\",ascending=True)[int(np.floor(population/10)):]\n",
    "            for index , parent in elites.iterrows():\n",
    "                av_index = [i for i in elites.index]\n",
    "                av_index.remove(index)\n",
    "                target = av_index[np.random.randint(0,len(av_index))]\n",
    "                av_index.remove(target)\n",
    "                random1 = av_index[np.random.randint(0,len(av_index))]\n",
    "                av_index.remove(random1)\n",
    "                random2 = av_index[np.random.randint(0,len(av_index))]\n",
    "                av_index.remove(random2)\n",
    "                trial = mutation_DE(dframe.loc[index],dframe.loc[target],dframe.loc[random1],dframe.loc[random2],Adj,0.5)\n",
    "                offspring = crossover_DE(parent, trial, 0.8)\n",
    "                off_subsets = find_subsets(offspring)\n",
    "                off_c_score = community_score(offspring, off_subsets, r , Adj)\n",
    "                dframe.loc[population_count]=[offspring, off_subsets,off_c_score]\n",
    "                population_count += 1\n",
    "        dfsorted = dframe.sort_values(\"community_score\",ascending=False)\n",
    "        to_drop = dfsorted.index[population:]\n",
    "        dframe.drop(to_drop,inplace=True)\n",
    "        gen +=1   \n",
    "    sorted_df = dframe.sort_values(\"community_score\",ascending=False).index[0]\n",
    "    res = dframe.loc[sorted_df]\n",
    "    nodes_subsets = res[\"subsets\"]\n",
    "    res = res['chrom']\n",
    "#     istrue = check_res(res,Adj)\n",
    "#     print(istrue)\n",
    "    nodes_list = list(graph.nodes())\n",
    "    result = []\n",
    "    for subs in nodes_subsets:\n",
    "        subset = []\n",
    "        for n in subs:\n",
    "            subset.append(nodes_list[n])\n",
    "        result.append(subset)\n",
    "    NMI = 0\n",
    "    clu = dframe.loc[sorted_df]\n",
    "    clu = clu['chrom']\n",
    "    clu = np.array(clu)\n",
    "    for index, target in dframe.iterrows():\n",
    "        temp = np.array(target['chrom'])\n",
    "        x = computeNMI(clu,temp)\n",
    "        NMI += x\n",
    "    NMI /= len(dframe)\n",
    "    modularity = nx_comm.modularity(graph, result)\n",
    "    return result, NMI, modularity\n",
    "print(\"DE loaded to use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a94b4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSO loaded to use\n"
     ]
    }
   ],
   "source": [
    "#particle swarn optimization main function\n",
    "def PSO(nodes,edges,population=15,generation=100,r=1.5):\n",
    "    graph=nx.Graph() \n",
    "    graph.add_nodes_from(nodes) #adds nodes\n",
    "    graph.add_edges_from(edges) #add edges\n",
    "    Adj = nx.adjacency_matrix(graph) \n",
    "    nodes_length = len(graph.nodes())\n",
    "#     nx.draw(graph, with_labels=True,node_color = \"red\")\n",
    "#     plt.show()\n",
    "    d = {\"chrom\":[generate_chrom(nodes_length,Adj) for n in range(population)]}\n",
    "    dframe = pd.DataFrame(data= d)\n",
    "    dframe[\"subsets\"] = dframe[\"chrom\"].apply(find_subsets)\n",
    "    dframe[\"community_score\"]=dframe.apply(lambda x: community_score(x[\"chrom\"],x[\"subsets\"],r,Adj),axis=1)\n",
    "    W = 0.8\n",
    "    c1 = 0.3\n",
    "    c2 = 0.7\n",
    "    V = [np.random.randint(-nodes_length/3, nodes_length/3)]*len(dframe)\n",
    "    dframe[\"vel\"] = V\n",
    "    population_count = population\n",
    "    gen = 0\n",
    "    localbest= []\n",
    "    globalbest=[]\n",
    "    while gen < generation:\n",
    "        for i in range(int(np.floor(population/10))):\n",
    "            localbest = dframe\n",
    "            if gen!=0:\n",
    "                for index , particle in dframe.iterrows():\n",
    "                    CC = particle['chrom']\n",
    "                    LBC = localbest.loc[index]['chrom']\n",
    "                    GBC = globalbest['chrom']\n",
    "                    newvel=0\n",
    "                    for gene in range(0,len(particle['chrom'])):\n",
    "                        vel = (W*particle['vel']) + c1*(np.random.rand())*(LBC[gene]-CC[gene]) + c2*(np.random.rand())*(GBC[gene]-CC[gene])\n",
    "                        newgene = CC[gene] + int(vel)\n",
    "                        if newgene>=0 and newgene<Adj.shape[0] and Adj[gene,newgene] == 1:\n",
    "                            CC[gene] = newgene\n",
    "                        else:\n",
    "                            vel = particle['vel']\n",
    "                        newvel+=vel\n",
    "                    newvel /= len(particle['chrom'])\n",
    "                    newsub = find_subsets(CC)\n",
    "                    newscore = community_score(CC,newsub,r,Adj)\n",
    "                    if(newscore>localbest.loc[index]['community_score']):\n",
    "                        dframe.at[index,'subsets'] = newsub\n",
    "                        dframe.at[index,'chrom'] = [g for g in CC]\n",
    "                        dframe.at[index,'community_score'] = newscore\n",
    "                    dframe.at[index,'vel'] = newvel\n",
    "            globalbest = dframe.sort_values(\"community_score\",ascending=False).index[0]\n",
    "            globalbest = dframe.loc[globalbest]                   \n",
    "        gen +=1   \n",
    "    sorted_df = dframe.sort_values(\"community_score\",ascending=False).index[0]\n",
    "    res = dframe.loc[sorted_df]\n",
    "    nodes_subsets = res[\"subsets\"]\n",
    "    res = res['chrom']\n",
    "#     istrue = check_res(res,Adj)\n",
    "#     print(istrue)\n",
    "    nodes_list = list(graph.nodes())\n",
    "    result = []\n",
    "    for subs in nodes_subsets:\n",
    "        subset = []\n",
    "        for n in subs:\n",
    "            subset.append(nodes_list[n])\n",
    "        result.append(subset)\n",
    "    NMI = 0\n",
    "    clu = dframe.loc[sorted_df]\n",
    "    clu = clu['chrom']\n",
    "    clu = np.array(clu)\n",
    "    for index, target in dframe.iterrows():\n",
    "        temp = np.array(target['chrom'])\n",
    "        x = computeNMI(clu,temp)\n",
    "        NMI += x\n",
    "    NMI /= len(dframe)\n",
    "    modularity = nx_comm.modularity(graph, result)\n",
    "    return result, NMI, modularity\n",
    "print(\"PSO loaded to use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84ac6b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GWO loaded to use\n"
     ]
    }
   ],
   "source": [
    "#grey wolf optimization main function\n",
    "def GWO(nodes,edges,population=15,generation=100,r=1.5):\n",
    "    graph=nx.Graph() \n",
    "    graph.add_nodes_from(nodes) #adds nodes\n",
    "    graph.add_edges_from(edges) #add edges\n",
    "    Adj = nx.adjacency_matrix(graph) \n",
    "    nodes_length = len(graph.nodes())\n",
    "#     nx.draw(graph, with_labels=True,node_color = \"red\")\n",
    "#     plt.show()\n",
    "    d = {\"chrom\":[generate_chrom(nodes_length,Adj) for n in range(population)]}\n",
    "    dframe = pd.DataFrame(data= d)\n",
    "    dframe[\"subsets\"] = dframe[\"chrom\"].apply(find_subsets)\n",
    "    dframe[\"community_score\"]=dframe.apply(lambda x: community_score(x[\"chrom\"],x[\"subsets\"],r,Adj),axis=1)\n",
    "    gen = 0\n",
    "    population_count = population\n",
    "    while gen < generation:\n",
    "        for i in range(int(np.floor(population/10))):\n",
    "            elites = dframe.sort_values(\"community_score\",ascending=True)[int(np.floor(population/10)):]\n",
    "            best3 = dframe.sort_values(\"community_score\", ascending=False)[0:3]\n",
    "            xalpha = dframe.loc[best3.index[0]]['chrom']\n",
    "            xbeta = dframe.loc[best3.index[1]]['chrom']\n",
    "            xgamma = dframe.loc[best3.index[2]]['chrom']\n",
    "            a = 2*(1-(gen/generation))\n",
    "            for index , wolf in elites.iterrows():\n",
    "                A1 = (2*a*np.random.rand()) - a\n",
    "                C1 = 2*np.random.rand()\n",
    "                Dalpha = abs(C1*xalpha - wolf['chrom'])\n",
    "                X1 = abs(xalpha - (A1*Dalpha))\n",
    "                A2 = (2*a*np.random.rand()) - a\n",
    "                C2 = 2*np.random.rand()\n",
    "                Dbeta = abs(C2*xbeta - wolf['chrom'])\n",
    "                X2 = abs(xbeta - (A2*Dbeta))\n",
    "                A3 = (2*a*np.random.rand()) - a\n",
    "                C3 = 2*np.random.rand()\n",
    "                Dgamma = abs(C3*xgamma - wolf['chrom'])\n",
    "                X3 = abs(xgamma - (A3*Dgamma))\n",
    "                Xnew = (X1+X2+X3)/3\n",
    "                Xnew = np.array([int(i) for i in Xnew])\n",
    "                for i in range(0,len(Xnew)):\n",
    "                    if Xnew[i] < 0 or Xnew[i] >= Adj.shape[0] or Adj[i,Xnew[i]]==0:\n",
    "                        Xnew[i] = xalpha[i]\n",
    "                subsetnew = find_subsets(Xnew)\n",
    "                fscorenew = community_score(Xnew,subsetnew, r, Adj)\n",
    "                dframe.loc[population_count]=[Xnew,subsetnew,fscorenew]\n",
    "                population_count += 1\n",
    "        dfsorted = dframe.sort_values(\"community_score\",ascending=False)\n",
    "        to_drop = dfsorted.index[population:]\n",
    "        dframe.drop(to_drop,inplace=True)\n",
    "        gen +=1   \n",
    "    sorted_df = dframe.sort_values(\"community_score\",ascending=False).index[0]\n",
    "    res = dframe.loc[sorted_df]\n",
    "    res = res['chrom']\n",
    "#     istrue = check_res(res,Adj)\n",
    "#     print(istrue)\n",
    "    res_subsets = find_subsets(res)\n",
    "    nodes_subsets = res_subsets\n",
    "    nodes_list = list(graph.nodes())\n",
    "    result = []\n",
    "    for subs in nodes_subsets:\n",
    "        subset = []\n",
    "        for n in subs:\n",
    "            subset.append(nodes_list[n])\n",
    "        result.append(subset)\n",
    "    NMI = 0\n",
    "    clu = dframe.loc[sorted_df]\n",
    "    clu = clu['chrom']\n",
    "    clu = np.array(clu)\n",
    "    for index, target in dframe.iterrows():\n",
    "        temp = np.array(target['chrom'])\n",
    "        x = computeNMI(clu,temp)\n",
    "        NMI += x\n",
    "    NMI /= len(dframe)\n",
    "    modularity = nx_comm.modularity(graph, result)\n",
    "    return result, NMI, modularity\n",
    "print(\"GWO loaded to use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dad784e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ready\n"
     ]
    }
   ],
   "source": [
    "#read file(create edges and nodes)\n",
    "\n",
    "nodes = []\n",
    "edges = np.loadtxt('Sawmill.txt')\n",
    "for i in edges:\n",
    "    for j in i:\n",
    "        if j not in nodes:\n",
    "            nodes.append(int(j))\n",
    "print(\"Data ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56ac205f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table ready\n"
     ]
    }
   ],
   "source": [
    "#result table\n",
    "table = [['Sawmill', 'GE', 'DE', 'PSO', 'GWO','WOA'],\n",
    "        ['Avg NMI', 0, 0, 0, 0, 0],\n",
    "        ['Max NMI', 0, 0, 0, 0, 0],\n",
    "        ['Min NMI', 0, 0, 0, 0, 0],\n",
    "        ['Avg Mod', 0, 0, 0, 0, 0],\n",
    "        ['Max Mod', 0, 0, 0, 0, 0],\n",
    "        ['Min Mod', 0, 0, 0, 0, 0]]\n",
    "print(\"Table ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f67309b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GE 1\n",
      "GE 2\n",
      "GE 3\n",
      "GE 4\n",
      "GE 5\n",
      "GE 6\n",
      "GE 7\n",
      "GE 8\n",
      "GE 9\n",
      "GE 10\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#genetic algorithm\n",
    "NMI_arr_GE = []\n",
    "mod_arr_GE = []\n",
    "bst_arr_GE = []\n",
    "\n",
    "for i in range(0,10):\n",
    "    print(\"GE\",i+1)\n",
    "    best_community, NMI, modularity = genetic_evolution(nodes,edges)\n",
    "    NMI_arr_GE.append(NMI)\n",
    "    mod_arr_GE.append(modularity)\n",
    "    bst_arr_GE.append(best_community)\n",
    "    \n",
    "NMI_avg_GE = sum(NMI_arr_GE)/len(NMI_arr_GE)\n",
    "mod_avg_GE = sum(mod_arr_GE)/len(mod_arr_GE)\n",
    "NMI_bst_GE = max(NMI_arr_GE)  #best\n",
    "mod_bst_GE = max(mod_arr_GE)\n",
    "NMI_lst_GE = min(NMI_arr_GE)  #least\n",
    "mod_lst_GE = min(mod_arr_GE)\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Genetic Algorithm\")\n",
    "# print('NMI avg: ', NMI_avg_GE)\n",
    "# print('NMI max: ', NMI_bst_GE)\n",
    "# print('NMI min: ', NMI_lst_GE)\n",
    "# print()\n",
    "# print('mod avg: ', mod_avg_GE)\n",
    "# print('mod max: ', mod_bst_GE)\n",
    "# print('mod min: ', mod_lst_GE)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f018f00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DE 1\n",
      "DE 2\n",
      "DE 3\n",
      "DE 4\n",
      "DE 5\n",
      "DE 6\n",
      "DE 7\n",
      "DE 8\n",
      "DE 9\n",
      "DE 10\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#differential algorithm\n",
    "NMI_arr_DE = []\n",
    "mod_arr_DE = []\n",
    "bst_arr_DE = []\n",
    "\n",
    "for i in range(0,10):\n",
    "    print(\"DE\",i+1)\n",
    "    best_community, NMI, modularity = differential_evolution(nodes,edges)\n",
    "    NMI_arr_DE.append(NMI)\n",
    "    mod_arr_DE.append(modularity)\n",
    "    bst_arr_DE.append(best_community)\n",
    "    \n",
    "NMI_avg_DE = sum(NMI_arr_DE)/len(NMI_arr_DE)\n",
    "mod_avg_DE = sum(mod_arr_DE)/len(mod_arr_DE)\n",
    "NMI_bst_DE = max(NMI_arr_DE)  #best\n",
    "mod_bst_DE = max(mod_arr_DE)\n",
    "NMI_lst_DE = min(NMI_arr_DE)  #least\n",
    "mod_lst_DE = min(mod_arr_DE)\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Differential Algorithm\")\n",
    "# print('NMI avg: ', NMI_avg_DE)\n",
    "# print('NMI max: ', NMI_bst_DE)\n",
    "# print('NMI min: ', NMI_lst_DE)\n",
    "# print()\n",
    "# print('mod avg: ', mod_avg_DE)\n",
    "# print('mod max: ', mod_bst_DE)\n",
    "# print('mod min: ', mod_lst_DE)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a4f85ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSO 1\n",
      "PSO 2\n",
      "PSO 3\n",
      "PSO 4\n",
      "PSO 5\n",
      "PSO 6\n",
      "PSO 7\n",
      "PSO 8\n",
      "PSO 9\n",
      "PSO 10\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#PSO\n",
    "NMI_arr_PSO = []\n",
    "mod_arr_PSO = []\n",
    "bst_arr_PSO = []\n",
    "\n",
    "for i in range(0,10):\n",
    "    print(\"PSO\",i+1)\n",
    "    best_community, NMI, modularity = PSO(nodes,edges)\n",
    "    NMI_arr_PSO.append(NMI)\n",
    "    mod_arr_PSO.append(modularity)\n",
    "    bst_arr_PSO.append(best_community)\n",
    "    \n",
    "NMI_avg_PSO = sum(NMI_arr_PSO)/len(NMI_arr_PSO)\n",
    "mod_avg_PSO = sum(mod_arr_PSO)/len(mod_arr_PSO)\n",
    "NMI_bst_PSO = max(NMI_arr_PSO)  #best\n",
    "mod_bst_PSO = max(mod_arr_PSO)\n",
    "NMI_lst_PSO = min(NMI_arr_PSO)  #least\n",
    "mod_lst_PSO = min(mod_arr_PSO)\n",
    "\n",
    "\n",
    "# print(\"PSO\")\n",
    "# print('NMI avg: ', NMI_avg_PSO)\n",
    "# print('NMI max: ', NMI_bst_PSO)\n",
    "# print('NMI min: ', NMI_lst_PSO)\n",
    "# print()\n",
    "# print('mod avg: ', mod_avg_PSO)\n",
    "# print('mod max: ', mod_bst_PSO)\n",
    "# print('mod min: ', mod_lst_PSO)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a80e761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GWO 1\n",
      "GWO 2\n",
      "GWO 3\n",
      "GWO 4\n",
      "GWO 5\n",
      "GWO 6\n",
      "GWO 7\n",
      "GWO 8\n",
      "GWO 9\n",
      "GWO 10\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#GWO\n",
    "NMI_arr_GWO = []\n",
    "mod_arr_GWO = []\n",
    "bst_arr_GWO = []\n",
    "\n",
    "for i in range(0,10):\n",
    "    print(\"GWO\",i+1)\n",
    "    best_community, NMI, modularity = GWO(nodes,edges)\n",
    "    NMI_arr_GWO.append(NMI)\n",
    "    mod_arr_GWO.append(modularity)\n",
    "    bst_arr_GWO.append(best_community)\n",
    "    \n",
    "NMI_avg_GWO = sum(NMI_arr_GWO)/len(NMI_arr_GWO)\n",
    "mod_avg_GWO = sum(mod_arr_GWO)/len(mod_arr_GWO)\n",
    "NMI_bst_GWO = max(NMI_arr_GWO)  #best\n",
    "mod_bst_GWO = max(mod_arr_GWO)\n",
    "NMI_lst_GWO = min(NMI_arr_GWO)  #least\n",
    "mod_lst_GWO = min(mod_arr_GWO)\n",
    "\n",
    "\n",
    "# print(\"GWO\")\n",
    "# print('NMI avg: ', NMI_avg_GWO)\n",
    "# print('NMI max: ', NMI_bst_GWO)\n",
    "# print('NMI min: ', NMI_lst_GWO)\n",
    "# print()\n",
    "# print('mod avg: ', mod_avg_GWO)\n",
    "# print('mod max: ', mod_bst_GWO)\n",
    "# print('mod min: ', mod_lst_GWO)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9b57f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def AssignColor(i,Adj):\n",
    "#     N = Adj.shape[0]\n",
    "#     color = np.zeros(N,dtype=int)\n",
    "#     val = 0\n",
    "#     for j in i[\"subsets\"]:\n",
    "#         for k in j:\n",
    "#             color[k] = val\n",
    "#         val+=1\n",
    "#     return color\n",
    "\n",
    "# def findIndex(i,color,target):\n",
    "#     arr = i[\"subsets\"]\n",
    "#     for i in range(len(arr)):\n",
    "#         for j in range(len(arr[i])):\n",
    "#             if (arr[i][j] == target):\n",
    "#                 return j\n",
    "            \n",
    "\n",
    "def ShrinkingEncircling(i,P_se,Adj):\n",
    "    \n",
    "    N = Adj.shape[0]\n",
    "    n = N*P_se\n",
    "    color = np.zeros(N,dtype=int)\n",
    "    val = 0\n",
    "    for j in i[\"subsets\"]:\n",
    "        for k in j:\n",
    "            color[k] = val\n",
    "        val+=1\n",
    "    \n",
    "    \n",
    "        \n",
    "    for z in range(0,int(n)):\n",
    "        index = random.randrange(0,N)\n",
    "        freq = np.zeros(val, dtype = int)\n",
    "        for k in range(0, N):\n",
    "            if Adj[index,k] == 1:\n",
    "                freq[color[k]]+=1\n",
    "        max_freq = np.argmax(freq)\n",
    "        \n",
    "        for k in range(0, len(color)):\n",
    "            if(color[k] == max_freq and Adj[index,k] == 1):\n",
    "                i[\"chrom\"][index] = k\n",
    "                break\n",
    "    i[\"subsets\"] = find_subsets(i[\"chrom\"])\n",
    "    i[\"community_score\"] = community_score(i[\"chrom\"],i[\"subsets\"],1.5,Adj)\n",
    "    return i\n",
    "        \n",
    "# # Adj check for 1 , i(subset.index) , \n",
    "#     print(color)\n",
    "#     print(freq)\n",
    "#     print(max_freq)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "465bc051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomSearchingOperation(i,P_rs,Adj):\n",
    "    neigh = []\n",
    "#     color = AssignColor(i,Adj)\n",
    "    for j in i[\"chrom\"]:\n",
    "        r1 = np.random.rand()\n",
    "        if r1<=P_rs:\n",
    "            for k in range(0,Adj.shape[0]-1):\n",
    "                if Adj[j,k]==1:\n",
    "                    if j!=k:\n",
    "                        neigh.append(k)\n",
    "            if len(neigh)!=0:\n",
    "                ind = random.randrange(0,len(neigh))\n",
    "                i[\"chrom\"][j] = neigh[ind]\n",
    "                neigh.clear()\n",
    "    i[\"subsets\"] = find_subsets(i[\"chrom\"])\n",
    "    i[\"community_score\"] = community_score(i[\"chrom\"],i[\"subsets\"],1.5,Adj)\n",
    "    return i   \n",
    "           \n",
    "\n",
    "    \n",
    "def SpiralUpdatingOperation(i,P_su,gbest,Adj):\n",
    "    N = len(gbest[\"chrom\"])\n",
    "    n = N*P_su\n",
    "    for k in range(0,int(n)):\n",
    "        r = random.randrange(0,N)\n",
    "        i[\"chrom\"][r] = gbest[\"chrom\"][r]\n",
    "    \n",
    "    i[\"subsets\"] = find_subsets(i[\"chrom\"])\n",
    "    i[\"community_score\"] = community_score(i[\"chrom\"],i[\"subsets\"],1.5,Adj)\n",
    "    return i\n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b641b182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOA loaded to use\n"
     ]
    }
   ],
   "source": [
    "#particle swarn optimization main function\n",
    "def WOA(nodes,edges,population=15,generation=10,P_se=0.05, P_su = 0.05, P_rs = 0.1):\n",
    "    graph=nx.Graph() \n",
    "    graph.add_nodes_from(nodes) #adds nodes\n",
    "    graph.add_edges_from(edges) #add edges\n",
    "    Adj = nx.adjacency_matrix(graph) \n",
    "    nodes_length = len(graph.nodes())\n",
    "#     nx.draw(graph, with_labels=True,node_color = \"red\")\n",
    "#     plt.show()\n",
    "    d = {\"chrom\":[generate_chrom(nodes_length,Adj) for n in range(population)]}\n",
    "    dframe = pd.DataFrame(data= d)\n",
    "    dframe[\"subsets\"] = dframe[\"chrom\"].apply(find_subsets)\n",
    "    dframe[\"community_score\"]=dframe.apply(lambda x: community_score(x[\"chrom\"],x[\"subsets\"],1.5,Adj),axis=1)\n",
    "    population_count = population\n",
    "    gen = 0\n",
    "    globalbest=[]\n",
    "    globalbest = dframe.sort_values(\"community_score\",ascending=False).index[0]\n",
    "    globalbest = dframe.loc[globalbest]\n",
    "#     ShrinkingEncircling(dframe.loc[0],P_se, Adj)\n",
    "    while gen < generation:\n",
    "       \n",
    "        for i in range(int(np.floor(population/10))):\n",
    "            \n",
    "            r = np.random.rand()\n",
    "            a = (2-2*gen)/generation\n",
    "            M = (2*r-1)*a \n",
    "            if r < 0.5:\n",
    "                if abs(M) < 1:\n",
    "                    dframe.loc[i] = ShrinkingEncircling(dframe.loc[i],P_se, Adj)\n",
    "                elif abs(M)>=1:\n",
    "                    dframe.loc[i] = RandomSearchingOperation(dframe.loc[i],P_rs,Adj)\n",
    "            elif r>=0.5:\n",
    "                dframe.loc[i] = SpiralUpdatingOperation(dframe.loc[i],P_su,globalbest,Adj)\n",
    "        tempbest = dframe.sort_values(\"community_score\",ascending=False).index[0]\n",
    "        tempbest = dframe.loc[tempbest]\n",
    "        \n",
    "        if globalbest[\"community_score\"]<tempbest[\"community_score\"]:\n",
    "            globalbest = tempbest\n",
    "                           \n",
    "        gen +=1   \n",
    "   \n",
    "\n",
    "\n",
    "    res = globalbest\n",
    "    nodes_subsets = res[\"subsets\"]\n",
    "    res = res['chrom']\n",
    "#     istrue = check_res(res,Adj)\n",
    "#     print(istrue)\n",
    "    nodes_list = list(graph.nodes())\n",
    "    result = []\n",
    "    for subs in nodes_subsets:\n",
    "        subset = []\n",
    "        for n in subs:\n",
    "            subset.append(nodes_list[n])\n",
    "        result.append(subset)\n",
    "    NMI = 0\n",
    "    clu = globalbest\n",
    "    clu = clu['chrom']\n",
    "    clu = np.array(clu)\n",
    "    for index, target in dframe.iterrows():\n",
    "        temp = np.array(target['chrom'])\n",
    "        x = computeNMI(clu,temp)\n",
    "        NMI += x\n",
    "    NMI /= len(dframe)\n",
    "    modularity = nx_comm.modularity(graph, result)\n",
    "    return result, NMI, modularity\n",
    "print(\"WOA loaded to use\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8e889e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOA 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samar\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1056: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cacher_needs_updating = self._check_is_chained_assignment_possible()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOA 2\n",
      "WOA 3\n",
      "WOA 4\n",
      "WOA 5\n",
      "WOA 6\n",
      "WOA 7\n",
      "WOA 8\n",
      "WOA 9\n",
      "WOA 10\n",
      "WOA\n",
      "NMI avg:  0.8514650895105991\n",
      "NMI max:  0.871630037656381\n",
      "NMI min:  0.8305674065906908\n",
      "\n",
      "mod avg:  0.28543184183142556\n",
      "mod max:  0.408038501560874\n",
      "mod min:  0.14164932362122779\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#WOA\n",
    "NMI_arr_WOA = []\n",
    "mod_arr_WOA = []\n",
    "bst_arr_WOA = []\n",
    "\n",
    "for i in range(0,10):\n",
    "    print(\"WOA\",i+1)\n",
    "    best_community, NMI, modularity = WOA(nodes,edges)\n",
    "    NMI_arr_WOA.append(NMI)\n",
    "    mod_arr_WOA.append(modularity)\n",
    "    bst_arr_WOA.append(best_community)\n",
    "    \n",
    "NMI_avg_WOA = sum(NMI_arr_WOA)/len(NMI_arr_WOA)\n",
    "mod_avg_WOA = sum(mod_arr_WOA)/len(mod_arr_WOA)\n",
    "NMI_bst_WOA = max(NMI_arr_WOA)  #best\n",
    "mod_bst_WOA = max(mod_arr_WOA)\n",
    "NMI_lst_WOA = min(NMI_arr_WOA)  #least\n",
    "mod_lst_WOA = min(mod_arr_WOA)\n",
    "\n",
    "\n",
    "print(\"WOA\")\n",
    "print('NMI avg: ', NMI_avg_WOA)\n",
    "print('NMI max: ', NMI_bst_WOA)\n",
    "print('NMI min: ', NMI_lst_WOA)\n",
    "print()\n",
    "print('mod avg: ', mod_avg_WOA)\n",
    "print('mod max: ', mod_bst_WOA)\n",
    "print('mod min: ', mod_lst_WOA)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8c33b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "table[1][1] = NMI_avg_GE\n",
    "table[2][1] = NMI_bst_GE\n",
    "table[3][1] = NMI_lst_GE\n",
    "table[4][1] = mod_avg_GE\n",
    "table[5][1] = mod_bst_GE\n",
    "table[6][1] = mod_lst_GE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f71f4ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "table[1][2] = NMI_avg_DE\n",
    "table[2][2] = NMI_bst_DE\n",
    "table[3][2] = NMI_lst_DE\n",
    "table[4][2] = mod_avg_DE\n",
    "table[5][2] = mod_bst_DE\n",
    "table[6][2] = mod_lst_DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fa123c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "table[1][3] = NMI_avg_PSO\n",
    "table[2][3] = NMI_bst_PSO\n",
    "table[3][3] = NMI_lst_PSO\n",
    "table[4][3] = mod_avg_PSO\n",
    "table[5][3] = mod_bst_PSO\n",
    "table[6][3] = mod_lst_PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40be36ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "table[1][4] = NMI_avg_GWO\n",
    "table[2][4] = NMI_bst_GWO\n",
    "table[3][4] = NMI_lst_GWO\n",
    "table[4][4] = mod_avg_GWO\n",
    "table[5][4] = mod_bst_GWO\n",
    "table[6][4] = mod_lst_GWO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "319314a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "table[1][5] = NMI_avg_WOA\n",
    "table[2][5] = NMI_bst_WOA\n",
    "table[3][5] = NMI_lst_WOA\n",
    "table[4][5] = mod_avg_WOA\n",
    "table[5][5] = mod_bst_WOA\n",
    "table[6][5] = mod_lst_WOA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0686236e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Sawmill                  GE                  DE                 PSO                 GWO                 WOA\n",
      "             Avg NMI              0.9516              0.9915              0.9063              0.9977              0.8515\n",
      "             Max NMI              0.9891                 1.0              0.9418                 1.0              0.8716\n",
      "             Min NMI              0.8878              0.9674              0.8588              0.9913              0.8306\n",
      "             Avg Mod              0.3623              0.3515              0.3784              0.3623              0.2854\n",
      "             Max Mod              0.4199              0.3905              0.4655              0.4053               0.408\n",
      "             Min Mod              0.3066              0.3195              0.3222              0.3221              0.1416\n"
     ]
    }
   ],
   "source": [
    "#show table\n",
    "\n",
    "for i in range(1,len(table)):\n",
    "    for j in range(1,len(table[1])):\n",
    "        table[i][j] = np.around(table[i][j],4)\n",
    "\n",
    "format_row = \"{:>20}\" * (len(table[0]))\n",
    "for row in table:\n",
    "    print(format_row.format(*row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90ae545b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open ('MeanNMI.txt', 'a')\n",
    "file.write(table[0][0] + '\\n')\n",
    "for i in range(1,len(table[0])):\n",
    "    file.write(table[0][i] + \" \")\n",
    "\n",
    "file.write('\\n')\n",
    "for i in range(1,len(table[0])):\n",
    "    file.write(str(table[1][i])+ \" \")\n",
    "    \n",
    "    \n",
    "file.write('\\n')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ead0c7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open ('MeanMod.txt', 'a')\n",
    "file.write(table[0][0] + '\\n')\n",
    "for i in range(1,len(table[0])):\n",
    "    file.write(table[0][i] + \" \")\n",
    "\n",
    "file.write('\\n')\n",
    "for i in range(1,len(table[0])):\n",
    "    file.write(str(table[4][i])+ \" \")\n",
    "    \n",
    "file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b04249e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl as xl\n",
    "from openpyxl.chart import BarChart, Reference\n",
    "j=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572176c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = xl.load_workbook('empty.xlsx')\n",
    "i = str(j)\n",
    "j+=1\n",
    "wb.save('Dolphins'+i+'.xlsx')\n",
    "wb = xl.load_workbook('Dolphins'+i+'.xlsx')\n",
    "sheet = wb['Sheet1']\n",
    "\n",
    "for row in range(0,7):\n",
    "    for col in range(0,5):\n",
    "        cell = sheet.cell(row+1,col+1)\n",
    "        cell.value = table[row][col]\n",
    "values = Reference(sheet, min_row=1, max_row=sheet.max_row, min_col=2, max_col=5)\n",
    "\n",
    "chart = BarChart()\n",
    "chart.add_data(values,titles_from_data=True)\n",
    "chart.title = \"Dolphins\"\n",
    "x_titles = Reference(sheet, min_col=1, max_col=1, min_row=2, max_row=sheet.max_row)\n",
    "chart.set_categories(x_titles)\n",
    "\n",
    "sheet.add_chart(chart, 'j2')\n",
    "\n",
    "wb.save('Dolphins'+i+'.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
